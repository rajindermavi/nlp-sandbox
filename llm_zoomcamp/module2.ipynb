{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f6d67e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import random\n",
    "import numpy as np\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e2310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch\n",
    "from qdrant_client import QdrantClient, models\n",
    "from openai import OpenAI\n",
    "\n",
    "from fastembed import TextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551d280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74de88bc",
   "metadata": {},
   "source": [
    "### PARTS 2.1 - 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abbc827",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2ce2200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n",
    "\n",
    "collection_name = \"zoomcamp_llm_rag\"\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 512\n",
    "\n",
    "# Create the collection with specified vector parameters\n",
    "q_client = QdrantClient(\"http://localhost:6333\")\n",
    "\n",
    "q_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ccf8069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "id = 0\n",
    "\n",
    "for course in documents_raw:\n",
    "    for doc in course['documents']:\n",
    "        text = doc['question'] + ' ' + doc['text']\n",
    "        vector = models.Document(text=text, model=model_handle)\n",
    "        point = models.PointStruct(\n",
    "            id=id,\n",
    "            vector=vector, #embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\n",
    "            payload={\n",
    "                \"text\": doc['text'],\n",
    "                \"section\": doc['section'],\n",
    "                \"question\":doc['question'],\n",
    "                \"course\": course['course']\n",
    "            } #save all needed metadata fields\n",
    "        )\n",
    "        points.append(point)\n",
    "\n",
    "        id += 1\n",
    "\n",
    "\n",
    "\n",
    "q_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8331d4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, limit=1):\n",
    "\n",
    "    results = q_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b58e255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Solution : It is another way to start it for remote hosting a mlflow server. For example, if you are multiple colleagues working together on something you most likely would not run mlflow on one laptop but rather everyone would connect to the same server running mlflow\\nAnswer by Christoffer Added by Akshit Miglani (akshit.miglani09@gmail.com)\",\n",
      "  \"section\": \"Module 2: Experiment tracking\",\n",
      "  \"question\": \"What does launching the tracking server locally mean?\"\n",
      "}\n",
      "What does launching the tracking server locally mean?\n"
     ]
    }
   ],
   "source": [
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course['documents'])\n",
    "\n",
    "print(json.dumps(course_piece, indent=2))\n",
    "q = course_piece['question']\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4025c43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Solution : It is another way to start it for remote hosting a mlflow server. For example, if you are multiple colleagues working together on something you most likely would not run mlflow on one laptop but rather everyone would connect to the same server running mlflow\\nAnswer by Christoffer Added by Akshit Miglani (akshit.miglani09@gmail.com)\",\n",
      "  \"section\": \"Module 2: Experiment tracking\",\n",
      "  \"question\": \"What does launching the tracking server locally mean?\",\n",
      "  \"course\": \"mlops-zoomcamp\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "result = search(q)\n",
    "print(json.dumps(result.points[0].payload,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72955ea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=2, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\" # exact matching on string metadata fields\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ee6677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_in_course(query, course=\"mlops-zoomcamp\", limit=1):\n",
    "\n",
    "    results = q_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle\n",
    "        ),\n",
    "        query_filter=models.Filter( # filter by course name\n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1856c6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\n",
      "Older news:[source1] [source2]\n"
     ]
    }
   ],
   "source": [
    "result = search_in_course(\"What if I submit homeworks late?\", \"data-engineering-zoomcamp\").points[0]\n",
    "print(result.payload['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d15c8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depends on whether the form will still be open. If you're lucky and it's open, you can submit your homework and it will be evaluated. if closed - it's too late.\n",
      "(Added by Rileen Sinha, based on answer by Alexey on Slack)\n"
     ]
    }
   ],
   "source": [
    "result = search_in_course(\"What if I submit homeworks late?\", \"machine-learning-zoomcamp\").points[0]\n",
    "print(result.payload['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bf8b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In order to obtain the certificate, completion of the final capstone project is mandatory. The completion of weekly homework assignments is optional, but they can contribute to your overall progress and ranking on the top 100 leaderboard.\n"
     ]
    }
   ],
   "source": [
    "result = search_in_course(\"What if I submit homeworks late?\", \"mlops-zoomcamp\").points[0]\n",
    "print(result.payload['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec977e8",
   "metadata": {},
   "source": [
    "### PART 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f28a7ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3096809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "364f5756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58cf5af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run Kafka, you can execute the following command in your project directory for the Java Kafka producer:\n",
      "\n",
      "```\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "```\n",
      "\n",
      "For Python, you need to create a virtual environment and install the necessary packages as follows:\n",
      "\n",
      "1. Create a virtual environment and install the dependencies:\n",
      "   ```bash\n",
      "   python -m venv env\n",
      "   source env/bin/activate  # On Windows, use env\\Scripts\\activate\n",
      "   pip install -r ../requirements.txt\n",
      "   ```\n",
      "\n",
      "2. Activate the virtual environment each time you need it with:\n",
      "   ```bash\n",
      "   source env/bin/activate  # On Windows, use env\\Scripts\\activate\n",
      "   ```\n",
      "\n",
      "Remember to deactivate it after you're done with:\n",
      "```bash\n",
      "deactivate\n",
      "```\n",
      "\n",
      "Make sure any necessary Docker images are also running if you're using Docker.\n"
     ]
    }
   ],
   "source": [
    "ans = rag('how do I run kafka?')\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d0f38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you can still enroll in the course even after it has started. You are eligible to submit the homework assignments, but keep in mind that there will be deadlines for submitting the final projects, so it's best not to leave things to the last minute.\n"
     ]
    }
   ],
   "source": [
    "ans = rag('The course has already started, can I still enroll?')\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ab28d6",
   "metadata": {},
   "source": [
    "### RAG with Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5014494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(question):\n",
    "    print('vector_search is used')\n",
    "    \n",
    "    course = 'data-engineering-zoomcamp'\n",
    "    query_points = q_client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document(\n",
    "            text=question,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        query_filter=models.Filter( \n",
    "            must=[\n",
    "                models.FieldCondition(\n",
    "                    key=\"course\",\n",
    "                    match=models.MatchValue(value=course)\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        limit=5,\n",
    "        with_payload=True\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for point in query_points.points:\n",
    "        results.append(point.payload)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def rag(query):\n",
    "    search_results = vector_search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be570057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search is used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'In the project directory, run:\\njava -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: How to run producer/consumer/kstreams/etc in terminal',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'For example, when running JsonConsumer.java, got:\\nConsuming form kafka started\\nRESULTS:::0\\nRESULTS:::0\\nRESULTS:::0\\nOr when running JsonProducer.java, got:\\nException in thread \"main\" java.util.concurrent.ExecutionException: org.apache.kafka.common.errors.SaslAuthenticationException: Authentication failed\\nSolution:\\nMake sure in the scripts in src/main/java/org/example/ that you are running (e.g. JsonConsumer.java, JsonProducer.java), the StreamsConfig.BOOTSTRAP_SERVERS_CONFIG is the correct server url (e.g. europe-west3 from example vs europe-west2)\\nMake sure cluster key and secrets are updated in src/main/java/org/example/Secrets.java (KAFKA_CLUSTER_KEY and KAFKA_CLUSTER_SECRET)',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Java Kafka: When running the producer/consumer/etc java scripts, no results retrieved or no message sent',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': 'If you have this error, it most likely that your kafka broker docker container is not working.\\nUse docker ps to confirm\\nThen in the docker compose yaml file folder, run docker compose up -d to start all the instances.',\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'kafka.errors.NoBrokersAvailable: NoBrokersAvailable',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Solution from Alexey: create a virtual environment and run requirements.txt and the python files in that environment.\\nTo create a virtual env and install packages (run only once)\\npython -m venv env\\nsource env/bin/activate\\npip install -r ../requirements.txt\\nTo activate it (you'll need to run it every time you need the virtual env):\\nsource env/bin/activate\\nTo deactivate it:\\ndeactivate\\nThis works on MacOS, Linux and Windows - but for Windows the path is slightly different (it's env/Scripts/activate)\\nAlso the virtual environment should be created only to run the python file. Docker images should first all be up and running.\",\n",
       "  'section': 'Module 6: streaming with kafka',\n",
       "  'question': 'Module “kafka” not found when trying to run producer.py',\n",
       "  'course': 'data-engineering-zoomcamp'},\n",
       " {'text': \"Below I have listed some steps I took to rectify this and potentially other minor errors, in Windows:\\nUse the git bash terminal in windows.\\nActivate python venv from git bash: source .venv/Scripts/activate\\nModify the seed_kafka.py file: in the first line, replace python3 with python.\\nNow from git bash, run the seed-kafka cmd. It should work now.\\nAdditional Notes:\\nYou can connect to the RisingWave cluster from Powershell with the command psql -h localhost -p 4566 -d dev -U root , otherwise it asks for a password.\\nThe equivalent of source commands.sh  in Powershell is . .\\\\commands.sh from the workshop directory.\\nHope this can save you from some trouble in case you're doing this workshop on Windows like I am.\\n—--------------------------------------------------------------------------------------\",\n",
       "  'section': 'Workshop 2 - RisingWave',\n",
       "  'question': 'Psycopg2 InternalError: Failed to run the query - when running the seed-kafka command after initial setup.',\n",
       "  'course': 'data-engineering-zoomcamp'}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search('how do I run kafka?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4322caeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search is used\n",
      "To run Kafka, you need to ensure that your Kafka broker is operational. If you encounter the error \"kafka.errors.NoBrokersAvailable,\" verify that your Kafka broker Docker container is running by executing `docker ps`. If it is not running, navigate to the folder containing your docker compose YAML file and run the command:\n",
      "\n",
      "```\n",
      "docker compose up -d\n",
      "```\n",
      "\n",
      "Once your Kafka broker is up and running, you can run your producer or consumer Java applications from the project directory with the following command:\n",
      "\n",
      "```\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "```\n",
      "\n",
      "Ensure you replace `<jar_name>` with the actual name of your jar file. Additionally, double-check that the `StreamsConfig.BOOTSTRAP_SERVERS_CONFIG` in your scripts is correctly pointing to your Kafka server URL and that your cluster key and secrets in `src/main/java/org/example/Secrets.java` are updated.\n"
     ]
    }
   ],
   "source": [
    "ans = rag('how do I run kafka?')\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71794eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_search is used\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Yes, you can still join the course even after the start date. You are eligible to submit the homeworks, but be aware that there will be deadlines for turning in the final projects, so it's best not to leave everything until the last minute.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'I just discovered the course. Can I still join it?'\n",
    "\n",
    "rag(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59160c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_client.create_collection(\n",
    "    collection_name=\"zoomcamp-sparse\",\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb06821b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_client.upsert(\n",
    "    collection_name=\"zoomcamp-sparse\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=uuid.uuid4().hex,\n",
    "            vector={\n",
    "                \"bm25\": models.Document(\n",
    "                    text=doc[\"text\"], \n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "            },\n",
    "            payload={\n",
    "                \"question\":doc[\"question\"],\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"section\": doc[\"section\"],\n",
    "                \"course\": course[\"course\"],\n",
    "            }\n",
    "        )\n",
    "        for course in documents_raw\n",
    "        for doc in course[\"documents\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d25049cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = q_client.query_points(\n",
    "        collection_name=\"zoomcamp-sparse\",\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\",\n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f83ba6a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"question\": \"How to output only a certain number of decimal places\",\n",
      "    \"text\": \"You can use round() function or f-strings\\nround(number, 4)  - this will round number up to 4 decimal places\\nprint(f'Average mark for the Homework is {avg:.3f}') - using F string\\nAlso there is pandas.Series. round idf you need to round values in the whole Series\\nPlease check the documentation\\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.round.html#pandas.Series.round\\nAdded by Olga Rudakova\",\n",
      "    \"section\": \"2. Machine Learning for Regression\",\n",
      "    \"course\": \"machine-learning-zoomcamp\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = search(\"pandas\")\n",
    "print(json.dumps(results[0].payload,indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "500351b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Both work in similar ways. That is, to convert categorical features to numerical variables for use in training the model. But the difference lies in the input. OneHotEncoder uses an array as input while DictVectorizer uses a dictionary.\\nBoth will produce the same result. But when we use OneHotEncoder, features are sorted alphabetically. When you use DictVectorizer you stack features that you want.\\nTanya Mard\",\n",
      "  \"section\": \"3. Machine Learning for Classification\",\n",
      "  \"question\": \"What is the difference between OneHotEncoder and DictVectorizer?\",\n",
      "  \"course\": \"machine-learning-zoomcamp\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "course = random.choice(documents_raw)\n",
    "course_piece = random.choice(course[\"documents\"])\n",
    "print(json.dumps(course_piece, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "095481d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"question\": \"What is the difference between OneHotEncoder and DictVectorizer?\",\n",
      "    \"text\": \"Both work in similar ways. That is, to convert categorical features to numerical variables for use in training the model. But the difference lies in the input. OneHotEncoder uses an array as input while DictVectorizer uses a dictionary.\\nBoth will produce the same result. But when we use OneHotEncoder, features are sorted alphabetically. When you use DictVectorizer you stack features that you want.\\nTanya Mard\",\n",
      "    \"section\": \"3. Machine Learning for Classification\",\n",
      "    \"course\": \"machine-learning-zoomcamp\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = search(course_piece[\"question\"])\n",
    "print(json.dumps(results[0].payload,indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e91a91",
   "metadata": {},
   "source": [
    "Let's create another collection that will keep both dense and sparse representations. Qdrant named vectors allow us to store multiple representations per point and it proves useful especially when we want to use mulitple models in our applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1fc89a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Create the collection with both vector types\n",
    "q_client.create_collection(\n",
    "    collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "    vectors_config={\n",
    "        # Named dense vector for jinaai/jina-embeddings-v2-small-en\n",
    "        \"jina-small\": models.VectorParams(\n",
    "            size=512,\n",
    "            distance=models.Distance.COSINE,\n",
    "        ),\n",
    "    },\n",
    "    sparse_vectors_config={\n",
    "        \"bm25\": models.SparseVectorParams(\n",
    "            modifier=models.Modifier.IDF,\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a971c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_client.upsert(\n",
    "    collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=uuid.uuid4().hex,\n",
    "            vector={\n",
    "                \"jina-small\": models.Document(\n",
    "                    text=doc[\"text\"],\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                \"bm25\": models.Document(\n",
    "                    text=doc[\"text\"], \n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "            },\n",
    "            payload={\n",
    "                \"question\":doc[\"question\"],\n",
    "                \"text\": doc[\"text\"],\n",
    "                \"section\": doc[\"section\"],\n",
    "                \"course\": course[\"course\"],\n",
    "            }\n",
    "        )\n",
    "        for course in documents_raw\n",
    "        for doc in course[\"documents\"]\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c402a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def multi_stage_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = q_client.query_points(\n",
    "        collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                # Prefetch ten times more results, then\n",
    "                # expected to return, so we can really rerank\n",
    "                limit=(10 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        query=models.Document(\n",
    "            text=query,\n",
    "            model=\"Qdrant/bm25\", \n",
    "        ),\n",
    "        using=\"bm25\",\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f645d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"text\": \"Both work in similar ways. That is, to convert categorical features to numerical variables for use in training the model. But the difference lies in the input. OneHotEncoder uses an array as input while DictVectorizer uses a dictionary.\\nBoth will produce the same result. But when we use OneHotEncoder, features are sorted alphabetically. When you use DictVectorizer you stack features that you want.\\nTanya Mard\",\n",
      "  \"section\": \"3. Machine Learning for Classification\",\n",
      "  \"question\": \"What is the difference between OneHotEncoder and DictVectorizer?\",\n",
      "  \"course\": \"machine-learning-zoomcamp\"\n",
      "}\n",
      "{\n",
      "    \"question\": \"What is the difference between OneHotEncoder and DictVectorizer?\",\n",
      "    \"text\": \"Both work in similar ways. That is, to convert categorical features to numerical variables for use in training the model. But the difference lies in the input. OneHotEncoder uses an array as input while DictVectorizer uses a dictionary.\\nBoth will produce the same result. But when we use OneHotEncoder, features are sorted alphabetically. When you use DictVectorizer you stack features that you want.\\nTanya Mard\",\n",
      "    \"section\": \"3. Machine Learning for Classification\",\n",
      "    \"course\": \"machine-learning-zoomcamp\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = multi_stage_search(course_piece[\"question\"])\n",
    "print(json.dumps(course_piece, indent=2))\n",
    "print(json.dumps(results[0].payload,indent = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b478b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rrf_search(query: str, limit: int = 1) -> list[models.ScoredPoint]:\n",
    "    results = q_client.query_points(\n",
    "        collection_name=\"zoomcamp-sparse-and-dense\",\n",
    "        prefetch=[\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"jinaai/jina-embeddings-v2-small-en\",\n",
    "                ),\n",
    "                using=\"jina-small\",\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "            models.Prefetch(\n",
    "                query=models.Document(\n",
    "                    text=query,\n",
    "                    model=\"Qdrant/bm25\",\n",
    "                ),\n",
    "                using=\"bm25\",\n",
    "                limit=(5 * limit),\n",
    "            ),\n",
    "        ],\n",
    "        # Fusion query enables fusion on the prefetched results\n",
    "        query=models.FusionQuery(fusion=models.Fusion.RRF),\n",
    "        with_payload=True,\n",
    "    )\n",
    "\n",
    "    return results.points\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9a0bef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"text\": \"Both work in similar ways. That is, to convert categorical features to numerical variables for use in training the model. But the difference lies in the input. OneHotEncoder uses an array as input while DictVectorizer uses a dictionary.\\nBoth will produce the same result. But when we use OneHotEncoder, features are sorted alphabetically. When you use DictVectorizer you stack features that you want.\\nTanya Mard\",\n",
      "    \"section\": \"3. Machine Learning for Classification\",\n",
      "    \"question\": \"What is the difference between OneHotEncoder and DictVectorizer?\",\n",
      "    \"course\": \"machine-learning-zoomcamp\"\n",
      "}\n",
      "{\n",
      "    \"question\": \"What is the difference between OneHotEncoder and DictVectorizer?\",\n",
      "    \"text\": \"Both work in similar ways. That is, to convert categorical features to numerical variables for use in training the model. But the difference lies in the input. OneHotEncoder uses an array as input while DictVectorizer uses a dictionary.\\nBoth will produce the same result. But when we use OneHotEncoder, features are sorted alphabetically. When you use DictVectorizer you stack features that you want.\\nTanya Mard\",\n",
      "    \"section\": \"3. Machine Learning for Classification\",\n",
      "    \"course\": \"machine-learning-zoomcamp\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results = rrf_search(course_piece[\"question\"])\n",
    "print(json.dumps(course_piece, indent=4))\n",
    "print(json.dumps(results[0].payload,indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff25844",
   "metadata": {},
   "source": [
    "## HOMEWORK 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24841779",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "Embedding the query\n",
    "\n",
    "Embed the query: 'I just discovered the course. Can I join now?'. Use the 'jinaai/jina-embeddings-v2-small-en' model.\n",
    "\n",
    "You should get a numpy array of size 512.\n",
    "\n",
    "What's the minimal value in this array?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b1fecda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.11726373885183883)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TextEmbedding(model_name=\"jinaai/jina-embeddings-v2-small-en\")\n",
    "\n",
    "embedded_query = list(model.embed(['I just discovered the course. Can I join now?']))\n",
    "\n",
    "min(embedded_query[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feffed6",
   "metadata": {},
   "source": [
    "### Answer 1\n",
    "\n",
    "-0.1173"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d840cf2",
   "metadata": {},
   "source": [
    "### Q2. Cosine similarity with another vector\n",
    "\n",
    "Now let's embed this document:\n",
    "\n",
    "doc = 'Can I still join the course after the start date?'\n",
    "\n",
    "What's the cosine similarity between the vector for the query and the vector for the document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c39cff27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "doc = ['Can I still join the course after the start date?']\n",
    "embedded_doc = list(model.embed(doc))\n",
    "\n",
    "print(np.linalg.norm(embedded_query[0]))\n",
    "print(np.linalg.norm(embedded_doc[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20060646",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9008528895674548)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_doc[0].dot(embedded_query[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de3833",
   "metadata": {},
   "source": [
    "### Answer 2\n",
    "0.9009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664d31b",
   "metadata": {},
   "source": [
    "### Question 3 + 4\n",
    "\n",
    "For Q3 and Q4 we will use these documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23fe5228",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise_documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8297551",
   "metadata": {},
   "source": [
    "### Question 3 Ranking by cosine\n",
    "\n",
    "Compute the embeddings for the text field, and compute the cosine between the query vector and all the documents.\n",
    "\n",
    "What's the document index with the highest similarity? (Indexing starts from 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b13fcd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76296847, 0.81823782, 0.80853974, 0.7133079 , 0.73044992])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise_texts = [ doc['text'] for doc in exercise_documents]\n",
    "\n",
    "embedded_exercise_texts = list(model.embed(exercise_texts))\n",
    "\n",
    "np.array(embedded_exercise_texts).dot(embedded_query[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883aef6",
   "metadata": {},
   "source": [
    "### Answer 3\n",
    "\n",
    "0.81823\n",
    "\n",
    "Document 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e3a79861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85145432, 0.84365942, 0.8408287 , 0.7755158 , 0.80860078])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exercise_texts = [ doc['question']+' '+doc['text'] for doc in exercise_documents]\n",
    "\n",
    "embedded_exercise_texts = list(model.embed(exercise_texts))\n",
    "\n",
    "np.array(embedded_exercise_texts).dot(embedded_query[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb31bf",
   "metadata": {},
   "source": [
    "### Answer 4\n",
    "\n",
    "0.8515\n",
    "\n",
    "Document 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc5fa2",
   "metadata": {},
   "source": [
    "### Question 5. Selecting the embedding model\n",
    "\n",
    "Now let's select a smaller embedding model. What's the smallest dimensionality for models in fastembed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e43cbe6",
   "metadata": {},
   "source": [
    "TextEmbedding.list_supported_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "902d3d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min dim: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'model': 'BAAI/bge-small-en',\n",
       "  'sources': {'hf': 'Qdrant/bge-small-en',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/BAAI-bge-small-en.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'BAAI/bge-small-en-v1.5',\n",
       "  'sources': {'hf': 'qdrant/bge-small-en-v1.5-onnx-q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.',\n",
       "  'license': 'mit',\n",
       "  'size_in_GB': 0.067,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-xs',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-xs',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'snowflake/snowflake-arctic-embed-s',\n",
       "  'sources': {'hf': 'snowflake/snowflake-arctic-embed-s',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'onnx/model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.13,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/all-MiniLM-L6-v2',\n",
       "  'sources': {'hf': 'qdrant/all-MiniLM-L6-v2-onnx',\n",
       "   'url': 'https://storage.googleapis.com/qdrant-fastembed/sentence-transformers-all-MiniLM-L6-v2.tar.gz',\n",
       "   '_deprecated_tar_struct': True},\n",
       "  'model_file': 'model.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.09,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}},\n",
       " {'model': 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2',\n",
       "  'sources': {'hf': 'qdrant/paraphrase-multilingual-MiniLM-L12-v2-onnx-Q',\n",
       "   'url': None,\n",
       "   '_deprecated_tar_struct': False},\n",
       "  'model_file': 'model_optimized.onnx',\n",
       "  'description': 'Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year.',\n",
       "  'license': 'apache-2.0',\n",
       "  'size_in_GB': 0.22,\n",
       "  'additional_files': [],\n",
       "  'dim': 384,\n",
       "  'tasks': {}}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supported_models = TextEmbedding.list_supported_models()\n",
    "\n",
    "supported_models_sizes = [ model_specs['dim'] for model_specs in supported_models ]\n",
    "min_dim = min(set(supported_models_sizes))\n",
    "print(f'Min dim: {min_dim}')\n",
    "smallest_models = [model_specs for model_specs in supported_models if model_specs['dim'] == min_dim]\n",
    "\n",
    "smallest_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bf0be8",
   "metadata": {},
   "source": [
    "### Answer 5\n",
    "\n",
    "smallest models dimension: 384"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ccc415",
   "metadata": {},
   "source": [
    "### Question 6 Indexing with Qdrant\n",
    "\n",
    "Use the small model BAAI/bge-small-en we found above to find the best document from the ml-zoomcamp course.\n",
    "\n",
    "What is the score of the best match for our query?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99fe04a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_documents = [\n",
    "    {**doc, 'course': course['course']}\n",
    "    for course in documents_raw\n",
    "    if course['course'] == 'machine-learning-zoomcamp'\n",
    "    for doc in course['documents']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab11fe46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=1, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_DIMENSIONALITY = 384\n",
    "model_handle = \"BAAI/bge-small-en\"\n",
    "collection_name = \"zoomcamp-ml-faq\"\n",
    "\n",
    "q_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,\n",
    "        distance=models.Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "q_client.create_payload_index(\n",
    "    collection_name=collection_name,\n",
    "    field_name=\"course\",\n",
    "    field_schema=\"keyword\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9099342b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=14, version=2, score=0.8703172, payload={'text': 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.', 'section': 'General course-related questions', 'question': 'The course has already started. Can I still join it?', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=6, version=2, score=0.86918855, payload={'text': 'Approximately 4 months, but may take more if you want to do some extra activities (an extra project, an article, etc)', 'section': 'General course-related questions', 'question': 'How long is the course?', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=13, version=2, score=0.86833113, payload={'text': \"Here’s how you join a in Slack: https://slack.com/help/articles/205239967-Join-a-channel\\nClick “All channels” at the top of your left sidebar. If you don't see this option, click “More” to find it.\\nBrowse the list of public channels in your workspace, or use the search bar to search by channel name or description.\\nSelect a channel from the list to view it.\\nClick Join Channel.\\nDo we need to provide the GitHub link to only our code corresponding to the homework questions?\\nYes. You are required to provide the URL to your repo in order to receive a grade\", 'section': 'General course-related questions', 'question': 'I’m new to Slack and can’t find the course channel. Where is it?', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=293, version=2, score=0.8576106, payload={'text': 'TODO', 'section': '10. Kubernetes and TensorFlow Serving', 'question': 'How to get started with Week 10?', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=17, version=2, score=0.85715395, payload={'text': 'Welcome to the course! Go to the course page (http://mlzoomcamp.com/), scroll down and start going through the course materials. Then read everything in the cohort folder for your cohort’s year.\\nClick on the links and start watching the videos. Also watch office hours from previous cohorts. Go to DTC youtube channel and click on Playlists and search for {course yyyy}. ML Zoomcamp was first launched in 2021.\\nOr you can just use this link: http://mlzoomcamp.com/#syllabus', 'section': 'General course-related questions', 'question': 'I just joined. What should I do next? How can I access course materials?', 'course': 'machine-learning-zoomcamp'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = []\n",
    "\n",
    "for i, doc in enumerate(ml_documents):\n",
    "    text = doc['question'] + ' ' + doc['text']\n",
    "    vector = models.Document(text=text, model=model_handle)\n",
    "    point = models.PointStruct(\n",
    "        id=i,\n",
    "        vector=vector,\n",
    "        payload=doc\n",
    "    )\n",
    "    points.append(point)\n",
    "\n",
    "q_client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")\n",
    "\n",
    "q = 'I just discovered the course. Can I join now?'\n",
    "\n",
    "query_points = q_client.query_points(\n",
    "    collection_name=collection_name,\n",
    "    query=models.Document(\n",
    "        text=q,\n",
    "        model=model_handle \n",
    "    ),\n",
    "    query_filter=models.Filter( \n",
    "        must=[\n",
    "            models.FieldCondition(\n",
    "                key=\"course\",\n",
    "                match=models.MatchValue(value='machine-learning-zoomcamp')\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    "    limit=5,\n",
    "    with_payload=True\n",
    ")\n",
    "\n",
    "query_points.points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c890a51",
   "metadata": {},
   "source": [
    "### Answer 6\n",
    "\n",
    "High score: 0.8703"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffa3947",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
