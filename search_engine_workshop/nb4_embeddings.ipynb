{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "600afa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84968272",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet('df_qa.parquet')\n",
    "with open(\"documents.pkl\", \"rb\") as f:\n",
    "    documents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0a45c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fields = ['section', 'question', 'text']\n",
    "transformers = {}\n",
    "matrices = {}\n",
    "\n",
    "for field in fields:\n",
    "    cv = TfidfVectorizer(stop_words='english', min_df=3)\n",
    "    X = cv.fit_transform(df[field])\n",
    "\n",
    "    transformers[field] = cv\n",
    "    matrices[field] = X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f6b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = matrices['text']\n",
    "cv = transformers['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7de2ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=16)\n",
    "X_emb = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61288a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.08800162, -0.07499894, -0.10116528,  0.05162712,  0.05252841,\n",
       "       -0.05927311,  0.01862466,  0.05495231, -0.1782485 ,  0.34135307,\n",
       "        0.07104485,  0.10346399, -0.07400803, -0.03461088,  0.01943664,\n",
       "        0.04118679])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc06fc81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.11643751658743406)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'I just signed up. Is it too late to join the course?'\n",
    "\n",
    "Q = cv.transform([query])\n",
    "Q_emb = svd.transform(Q)\n",
    "\n",
    "np.dot(X_emb[0], Q_emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245db681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       " \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       " 'No, late submissions are not allowed. But if the form is still not closed and it’s after the due date, you can still submit the homework. confirm your submission by the date-timestamp on the Course page.y\\nOlder news:[source1] [source2]',\n",
       " 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       " \"The process is automated now, so you should receive the email eventually. If you haven’t, check your promotions tab in Gmail as well as spam.\\nIf you unsubscribed from our newsletter, you won't get course related updates too.\\nBut don't worry, it’s not a problem. To make sure you don’t miss anything, join the #course-ml-zoomcamp channel in Slack and our telegram channel with announcements. This is enough to follow the course.\",\n",
       " 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       " 'The course is available in the self-paced mode too, so you can go through the materials at any time. But if you want to do it as a cohort with other students, the next iterations will happen in September 2023, September 2024 (and potentially other Septembers as well).',\n",
       " 'If you have submitted two projects (and peer-reviewed at least 3 course-mates’ projects for each submission), you will get the certificate for the course. According to the course coordinator, Alexey Grigorev, only two projects are needed to get the course certificate.\\n(optional) David Odimegwu',\n",
       " 'Please choose the closest one to your answer. Also do not post your answer in the course slack channel.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "\n",
    "idx = np.argsort(-score)[:10]\n",
    "\n",
    "df.with_row_index().filter(pl.col(\"index\").is_in(idx))['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe901a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.30502172,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf = NMF(n_components=16)\n",
    "X_emb = nmf.fit_transform(X)\n",
    "X_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "708b4744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.0008943 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17215064,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00055816,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = cv.transform([query])\n",
    "Q_emb = nmf.transform(Q)\n",
    "Q_emb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c944b183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
       " \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
       " 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
       " \"No, you can only get a certificate if you finish the course with a “live” cohort. We don't award certificates for the self-paced mode. The reason is you need to peer-review capstone(s) after submitting a project. You can only peer-review projects at the time the course is running.\",\n",
       " 'The course videos are pre-recorded, you can start watching the course right now.\\nWe will also occasionally have office hours - live sessions where we will answer your questions. The office hours sessions are recorded too.\\nYou can see the office hours as well as the pre-recorded course videos in the course playlist on YouTube.',\n",
       " 'Everything is recorded, so you won’t miss anything. You will be able to ask your questions for office hours in advance and we will cover them during the live stream. Also, you can always ask questions in Slack.',\n",
       " 'Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\\nIn order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.',\n",
       " 'No, it’s not possible. The form is closed after the due date. But don’t worry, homework is not mandatory for finishing the course.',\n",
       " 'If you have submitted two projects (and peer-reviewed at least 3 course-mates’ projects for each submission), you will get the certificate for the course. According to the course coordinator, Alexey Grigorev, only two projects are needed to get the course certificate.\\n(optional) David Odimegwu',\n",
       " 'Please choose the closest one to your answer. Also do not post your answer in the course slack channel.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "score = cosine_similarity(X_emb, Q_emb).flatten()\n",
    "idx = np.argsort(-score)[:10]\n",
    "df.with_row_index().filter(pl.col(\"index\").is_in(idx))['text'].to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d4496a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "model.eval()  # Set the model to evaluation mode if not training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57ae1cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2748,  1010,  2057,  2097,  2562,  2035,  1996,  4475,  2044,\n",
       "          1996,  2607, 12321,  1012,   102],\n",
       "        [  101,  2017,  2064,  3582,  1996,  2607,  2012,  2115,  2219,  6393,\n",
       "          2044,  2009, 12321,   102,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Yes, we will keep all the materials after the course finishes.\",\n",
    "    \"You can follow the course at your own pace after it finishes\"\n",
    "]\n",
    "encoded_input = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cea8e2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 15, 768])\n",
      "torch.Size([2, 768])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.3599924 , -0.16072305,  0.35452363, ...,  0.04289253,\n",
       "         0.03482319, -0.03822242],\n",
       "       [ 0.17849939, -0.5000251 ,  0.25277585, ..., -0.11413134,\n",
       "        -0.33608466,  0.4109512 ]], shape=(2, 768), dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():  # Disable gradient calculation for inference\n",
    "    outputs = model(**encoded_input)\n",
    "    hidden_states = outputs.last_hidden_state\n",
    "\n",
    "print(hidden_states.shape)\n",
    "\n",
    "sentence_embeddings = hidden_states.mean(dim=1)\n",
    "print(sentence_embeddings.shape)\n",
    "\n",
    "sentence_embeddings.numpy()\n",
    "\n",
    "# note that if use a GPU, first you need to move your tensors to CPU\n",
    "# sentence_embeddings_cpu = sentence_embeddings.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d96a9f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(seq, n):\n",
    "    result = []\n",
    "    for i in range(0, len(seq), n):\n",
    "        batch = seq[i:i+n]\n",
    "        result.append(batch)\n",
    "    return result\n",
    "\n",
    "def compute_embeddings(texts, batch_size=8):\n",
    "    text_batches = make_batches(texts, 8)\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    for batch in tqdm(text_batches):\n",
    "        encoded_input = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoded_input)\n",
    "            hidden_states = outputs.last_hidden_state\n",
    "            \n",
    "            batch_embeddings = hidden_states.mean(dim=1)\n",
    "            batch_embeddings_np = batch_embeddings.cpu().numpy()\n",
    "            all_embeddings.append(batch_embeddings_np)\n",
    "    \n",
    "    final_embeddings = np.vstack(all_embeddings)\n",
    "    return final_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0570c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing embeddings for section...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "816222d1fc8540efb2e38da87e5d3201",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing embeddings for question...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68370dc2c21f4c3db1de3a1c6690fc28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing embeddings for text...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e220d0962d4e1597934a7e28d0a575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = {}\n",
    "\n",
    "# fields = ['section', 'question', 'text']\n",
    "\n",
    "for f in fields:\n",
    "    print(f'computing embeddings for {f}...')\n",
    "    embeddings[f] = compute_embeddings(df[f].to_list())\n",
    "\n",
    "\n",
    "\n",
    "with open('embeddings.bin', 'wb') as file:\n",
    "    pickle.dump(embeddings,file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
